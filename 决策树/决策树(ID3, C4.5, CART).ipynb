{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 决策树是一种预测模型；决策树仅有单一输出，如果有多个输出，可以分别建立独立的决策树以处理不同的输出。如图所示：\n",
    "\n",
    "\n",
    "![](http://img.blog.csdn.net/20161121193225546)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本概念"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.信息熵\n",
    "信息熵(`information entropy`)定义为离散随机事件出现的概率，一个系统**越是稳定**，信息熵就**越低**，反之一个系统**越是混乱**，则它的信息熵**越高**；所以信息熵可以被认为是系统稳定性的一个度量。\n",
    "\n",
    "*如何计算信息熵？*\n",
    "\n",
    "对于有`K`个 类别的分类问题来说，假定样本集合`D`中第`k`类样本所占的比例为`p_k(k=1,2,...K)`， 则样本集合`D`的信息熵为:\n",
    "![image.png](./docs/xinxishang.png)\n",
    "\n",
    "### 2.信息增益\n",
    "信息增益是针对一个特定的分支标准，在该分支下计算原有数据的信息熵与引入该分支标准后的信息熵之差；\n",
    "\n",
    "**定义**\n",
    "\n",
    "![image.png](./docs/xinxizengyi.png)\n",
    "\n",
    "例如：\n",
    "![](./docs/xinxizengyi_lizi.png?raw=true)\n",
    "\n",
    "通过表1中天气的4个特征(`outlook, temperature, humidity, windy`)来分类目标(`play, not play`)\n",
    "\n",
    "![image.png](./docs/xixinzengyi_jie.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树构造"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3算法\n",
    "> ID3算法是一种贪心算法，用来构造决策树。ID3算法中根据特征选择和信息增益评估分支标准，每次选择**信息增益最大**的特征作为分支标准。\n",
    "\n",
    "#### 算法思想\n",
    "ID3算法的基本思想是：首先计算出原始数据集的信息熵，然后依次将数据中的每一个特征作为分支标准，并计算其相对于原始数据的信息增益，选择最大信息增益的分支标准来划分数据，因为信息增益越大，区分样本的能力就越强，越具有代表性。重复上述过程从而生成一棵决策树，很显然这是一种自顶向下的贪心策略。\n",
    "#### 算法缺陷\n",
    "+ 使用信息增益有一个缺点，那就是它会偏向于具有大量值的属性，也就是说在训练集中某个属性所取得不同值的个数越多，则越有可能选择它来作为分类属性，而这么做有时候是没有意义的；\n",
    "+ ID3算法不能处理连续分布的数据特征；"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C4.5算法\n",
    "> C4.5算法是对ID3算法的改进，它克服了ID3的**两个**缺点；对于离散的特征，C4.5算法**不直接使用**信息增益，而是使用**增益率(`gain ratio`)**来选择最优的分支标准；\n",
    "\n",
    "#### 增益率\n",
    "定义：\n",
    "\n",
    "![image.png](./docs/zengyilv.png?raw=true)\n",
    "\n",
    "#### 连续值属性处理方法\n",
    "对于连续属性值，C4.5算法处理的方法是**先把连续属性值转换为离散属性在进行处理；**虽然本质上属性的取值是连续的，但对于有限的采样数据它是离散的，如果有N条样本，那么我们有N-1种离散化的方法：<=vj的分到左子树，>vj的分到右子树。计算这N-1种情况下最大的信息增益率。在离散属性上只需要计算1次信息增益率，而在连续属性上却需要计算N-1次，计算量是相当大的。通过以下办法可以减少计算量：对于连续属性先按大小进行排序，只有在分类发生改变的地方才需要切开。例如：\n",
    "![image.png](./docs/C4.5.png?raw=true)\n",
    "\n",
    "对表中的连续属性Temperature进行分析，首先对样本根据Temperature属性值进行排序，结果如上表所示。在分类改变的地方(表中红线部分)进行切开，本来有13种离散化的情况，现在只需计算7种。\n",
    "\n",
    "如果利用增益率来选择连续值属性的分界点，会导致一些副作用。分界点将样本分成两个部分，这两个部分的样本个数之比也会影响增益率。根据增益率公式，我们可以发现，当分界点能够把样本分成数量相等的两个子集时（我们称此时的分界点为等分分界点），增益率的抑制会被最大化，因此等分分界点被过分抑制了。子集样本个数能够影响分界点，显然不合理。因此在决定分界点是还是采用增益这个指标，而选择属性的时候才使用增益率这个指标。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
